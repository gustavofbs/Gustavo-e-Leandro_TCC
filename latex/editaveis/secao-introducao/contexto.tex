\section{Contexto}\label{contextualizacao}

A qualidade de software mede o quanto um sistema atende às necessidades dos usuários, considerando padrões de desenvolvimento e requisitos definidos. Assim os padrões de desenvolvimento e os requisitos funcionam como critérios critérios de avaliação que ajudam a verificar se o sistema satisfaz tais necessidades \cite{ISO25010}. Esses modelos servem de base para medir, especificar e avaliar a qualidade de sistemas e softwares, tornando a verificação dos requisitos mais padronizada e consistente. É importante que os sistemas de software sejam avaliados quanto à sua qualidade para garantir que o produto atenda aos requisitos e gere valor aos stakeholders. A avaliação da qualidade deve considerar propriedades internas, como arquitetura, estrutura e código, e propriedades externas, como o comportamento do sistema em execução e a qualidade em uso, que representa o impacto real no usuário. Com essas medições, é possível prever problemas, garantir que o software cumpra os requisitos definidos e tornar o processo de desenvolvimento mais confiável e estruturado.

Apesar da existência de padrões consolidados, a indústria ainda enfrenta diversos problemas na medição e garantia de qualidade, especialmente em sistemas de software que utilizam interfaces gráficas e dinâmicas. Muitas aplicações, principalmente web, utilizam múltiplos frameworks de frontend com elementos reativos, o que dificulta a criação de testes automatizados por meio de LLMs. “As aplicações web modernas são caracterizadas por estruturas de navegação dinâmicas e complexas, nas quais cada página e cada interação do usuário fazem parte de uma rede intricada. As metodologias tradicionais de teste muitas vezes não conseguem explorar completamente esses caminhos complexos, especialmente quando as ações do usuário são interdependentes e sensíveis ao contexto” (\citeauthor{Mughal2025}, \citeyear{Mughal2025}, p. 1, tradução nossa).

A automação de testes com IA ainda enfrenta barreiras de cobertura, consistência e adaptação, pois ferramentas dependem de seletores frágeis, e os testes automatizados podem quebrar facilmente após mudanças visuais ou estruturais. Frameworks modernos de frontend podem gerar estruturas de DOM que tornam seletores e caminhos XPath instáveis, fazendo com que qualquer alteração de UI exija retrabalho para reescrever o código (\citeauthor{Pysmennyi2025}, \citeyear{Pysmennyi2025}). Os cenários de teste escritos em BDD frequentemente possuem alto nível de abstração, sem detalhes suficientes para identificar elementos da interface, o que torna a geração automática de testes uma tarefa complexa. “Cenários mal construídos podem levar a mal-entendidos, testes não confiáveis e ineficiências no processo de desenvolvimento” (\citeauthor{Alinezhadtilaki2025}, \citeyear{Alinezhadtilaki2025}, p. 1, tradução nossa). Assim, medir qualidade depende diretamente da forma como os elementos e interações são descritos.

Existem poucos estudos focados em gerar testes automaticamente a partir de cenários BDD, pois a maior parte das pesquisas concentra-se em transformar descrições em linguagem natural em testes para código como classes Java ou funções Python, e não em testes sobre interfaces gráficas, os quais exigem a identificação de elementos da UI \cite{Ferreira2025}. O presente trabalho busca investigar quais características textuais, estruturais e semânticas podem ser usadas ou ajustadas na escrita dos cenários BDD para favorecer o reconhecimento de elementos visuais por uma IA, possibilitando a geração de testes automatizados a partir de cenários escritos em BDD. Agentes de IA dependem de descrições mais estruturadas e de artefatos textuais explícitos para interpretar corretamente passos, elementos e estados intermediários das interfaces, enquanto métodos tradicionais como TDD e BDD não foram concebidos para lidar com sistemas baseados em LLM, pois assumem especificações estáveis e comportamentos determinísticos, o que contrasta com a natureza não determinística e adaptativa desses agentes \cite{Xia2025}.