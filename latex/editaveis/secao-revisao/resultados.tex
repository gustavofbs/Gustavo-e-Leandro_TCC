\section{Resultados}
\label{sec:rsl-resultados}

Após a definição da string de busca e a seleção dos estudos, procedeu-se à extração dos dados por meio do formulário disponibilizado na plataforma \textcolor{blue}{Parsifal}\todo[color=yellow]{Incluir nota de rodapé com a url}, escolhida por oferecer recursos que facilitam a condução estruturada de revisões na Engenharia de Software. Cada artigo incluído teve suas informações registradas no formulário, permitindo padronizar a coleta de dados. Concluída essa etapa, os resultados foram consolidados em uma \textcolor{blue}{planilha pública}\todo[color=yellow]{Incluir nota de rodapé com a url da planilha pública}, na qual cada linha corresponde a um estudo selecionado e cada coluna representa um dos campos definidos previamente no protocolo de extração. Essa organização possibilitou analisar de maneira sistemática os aspectos necessários para responder as questões de pesquisa secundárias deste estudo. Nas subseções seguintes, são apresentadas as sínteses obtidas a partir dessa extração.



\textcolor{blue}{planilha pública}\todo[color=yellow]{Incluir nota de rodapé com a url da planilha pública}


\subsection{Quais padrões e boas práticas de escrita em BDD já são utilizados para reduzir ambiguidades em cenários de teste?}

Os padrões e boas práticas de escrita em Behavior-Driven Development (BDD) desempenham um papel central na estruturação e no refinamento de cenários de teste, constituindo um mecanismo essencial para reduzir ambiguidades e promover um entendimento compartilhado entre stakeholders técnicos e não técnicos \cite{Alinezhadtilaki2025}. O elemento estruturante desse processo é a linguagem Gherkin, cuja natureza semiestruturada e legível \cite{Karpurapu2024} por humanos permite descrever comportamentos de forma clara e consistente \cite{Alinezhadtilaki2025} . O padrão fundamental utilizado é o modelo Given-When-Then, que define o comportamento esperado do sistema: o Given estabelece o contexto inicial ou as pré-condições relevantes; o When descreve a ação executada pelo usuário ou pelo sistema que desencadeia o comportamento analisado; e o Then especifica o resultado esperado após a conclusão da ação \cite{GUPTA2023102141}.

Segundo \cite{Alinezhadtilaki2025}, a escrita eficaz de cenários BDD depende da adesão rigorosa a essa estrutura e da clareza da linguagem empregada, de modo a minimizar subjetividades e eliminar ambiguidades. A conformidade estrita com o formato “Given, When, Then” contribui para a uniformidade da comunicação entre equipes, reduzindo falhas interpretativas e inconsistências na implementação. Além disso, espera-se que os cenários apresentem atributos como unicidade, integridade, clareza e foco, de forma que a descrição dos comportamentos seja acessível e facilmente operacionalizável. Outro princípio importante é a restrição da granularidade: cada cenário deve contemplar apenas uma ação realizada por um único tipo de usuário sobre um único objeto \cite{GUPTA2023102141}. Caso múltiplas ações ou objetos sejam envolvidos, recomenda-se a decomposição em cenários menores e mais específicos \cite{GUPTA2023102141}. Para ampliar a reutilização e abrangência dos testes, emprega-se também o padrão Scenario Outline \cite{Paduraru2025}, associado a tabelas de Examples, o que possibilita testar diversas instâncias de um mesmo modelo de comportamento sem redundância. A isso somam-se modelos de requisitos restritos, como o RUCM (Restricted Use Case Modeling) \cite{Wang2022}, que, ao incorporar templates com palavras-chave e regras rígidas de construção, contribuem para reduzir imprecisões e aumentar o potencial de análise automatizada das especificações, mesmo permitindo o uso do vocabulário completo do inglês desde que com complexidade sintática limitada.

A utilização de técnicas e ferramentas de suporte, especialmente com a incorporação de recursos de Inteligência Artificial, tem se mostrado decisiva para garantir a consistência dos padrões de escrita e a mitigação de ambiguidades. Ferramentas de validação sintática, como o Gherkin-lint \cite{Karpurapu2024}, são usadas para identificar violações de sintaxe e assegurar conformidade com diretrizes de estilo, superando limitações inerentes à revisão manual. Na geração automatizada de cenários BDD por meio de Large Language Models (LLMs), destaca-se o uso de few-shot prompting \cite{Karpurapu2024}, técnica que, ao fornecer exemplos previamente curados, aumenta a precisão dos cenários produzidos e reduz erros sintáticos \cite{Karpurapu2024}. Adicionalmente, métodos de Retrieval-Augmented Generation (RAG) enriquecem o contexto fornecido aos modelos com dados internos, como documentação e conhecimento organizacional, resultando em cenários mais completos e alinhados com a lógica de negócio \cite{Pysmennyi2025}. A participação humana por meio da abordagem human-in-the-loop permanece indispensável, pois permite que especialistas revisem, ajustem e validem os cenários gerados, garantindo sua aderência ao comportamento esperado do sistema \cite{Pysmennyi2025}.

\subsection{Quais são os principais desafios técnicos que os sistemas de IA enfrentam ao interpretar especificações BDD para identificar elementos da interface gráfica?}

Os sistemas de Inteligência Artificial (IA), em especial os Large Language Models (LLMs) e agentes autônomos, enfrentam desafios técnicos substanciais ao interpretar especificações em Behavior-Driven Development (BDD) para identificar e interagir com elementos de Interfaces Gráficas do Usuário (GUIs). Esses desafios concentram-se principalmente na tradução de linguagem natural para ações concretas, na necessidade de lidar com a natureza dinâmica e visual das interfaces modernas e nas limitações inerentes dos próprios modelos de IA. 

A interpretação das especificações escritas em Gherkin envolve dificuldades semânticas e contextuais. Entre elas, destaca-se o mapeamento inconsistente entre instruções em linguagem natural e as funcionalidades do sistema, bem como os parâmetros adequados para operar sobre os elementos da GUI \cite{Paduraru2025}, o que ocorre com frequência quando o modelo não é orientado por \textit{prompts} otimizados \cite{Pysmennyi2025}. Soma-se a isso, a presença de ambiguidades ou lacunas de contexto, onde a IA frequentemente não reconhece critérios de aceitação implícitos que não foram explicitamente registrados no cenário BDD, como a necessidade de solicitar confirmação ao usuário \cite{Zhang2025}. Outro desafio decorre da inconsistência de vocabulário e do uso de termos técnicos, especialmente quando nomes de classes, atributos ou métodos são compostos por acrônimos ou apresentam ambiguidades estruturais, o que dificulta a correspondência correta com os elementos de software \cite{Wang2022}. Problemas adicionais surgem da conversão de valores expressos em linguagem natural para tipos de dados esperados pelas funções do sistema, como na compatibilização de parâmetros com unidades de medida distintas ou nomenclaturas pouco transparentes \cite{Paduraru2025}. Ademais, os LLMs podem perder o foco na lógica de negócio essencial quando expostos a muitos detalhes contextuais, gerando código que, embora coerente com o cenário BDD, negligencia funcionalidades básicas \cite{Zhang2025}.

Além das dificuldades linguísticas, os sistemas de IA enfrentam barreiras relacionadas à interpretação visual e à adaptação dinâmica exigida por interfaces gráficas contemporâneas. A navegação em ambientes com estruturas complexas, estados interdependentes e elementos sensíveis ao contexto ultrapassa a capacidade dos métodos tradicionais de teste e requer agentes capazes de ajustar seu comportamento dinamicamente \cite{Mughal2025}.Selecionar observações relevantes é outro desafio, especialmente em contextos visuais complexos, como jogos eletrônicos ou interfaces gráficas ricas em elementos. Nesses cenários, definir funções de recompensa adequadas e filtrar sinais pertinentes são dificuldades típicas enfrentadas por abordagens de Aprendizado por Reforço (RL) \cite{Mastain2024}. Além disso, efeitos gráficos intensos, partículas e elementos visuais sobrepostos podem afetar ferramentas baseadas em visão computacional, dificultando a detecção de objetos, a identificação de estados relevantes ou a interpretação precisa de elementos que aparecem em condições de alta intensidade visual \cite{Paduraru2022}.

Por fim, as limitações estruturais dos próprios modelos de IA introduzem desafios adicionais. A natureza de “caixa preta” dos LLMs dificulta a obtenção de explicações claras sobre suas decisões, tornando mais complexa a depuração e o projeto de casos de teste \cite{Pysmennyi2025}. O comportamento probabilístico desses modelos resulta em não determinismo e na ocorrência de "alucionações", isto é, respostas plausíveis porém incorretas, o que complica o processo de validação, já que nem sempre é evidente qual deveria ser o resultado esperado \cite{Freeman2025}. Modelos menores também enfrentam limitações de planejamento e raciocínio, podendo entrar em ciclos improdutivos ou ficar presos na execução repetitiva de subtarefas quando confrontados com problemas complexos que exigem raciocínio multietapas \cite{Pysmennyi2025}. Adicionalmente, agentes de IA tendem a evitar cenários de teste negativos ao tentar “corrigir” o fluxo de execução para alcançar um resultado positivo, o que pode mascarar falhas críticas e aumentar o risco de falsos negativos \cite{Pysmennyi2025}.

\subsection{Que técnicas de NLP (Processamento de Linguagem Natural) têm sido aplicadas para melhorar a interpretação automática de requisitos em BDD?}

As técnicas de Processamento de Linguagem Natural (NLP) têm desempenhado um papel fundamental no aprimoramento da interpretação automática de requisitos e cenários em Behavior-Driven Development (BDD), especialmente com o avanço dos Large Language Models (LLMs). Essas técnicas buscam traduzir construções em linguagem natural (particularmente aquelas expressas em Gherkin) em formatos estruturados, verificáveis e automatizáveis, contribuindo para maior eficiência e qualidade no ciclo de testes. Entre as abordagens mais relevantes, destacam-se as aplicações diretas de LLMs, que atuam como motores para a interpretação e geração de artefatos BDD graças à sua capacidade de compreensão contextual da linguagem natural. Os modelos têm sido utilizados para a geração automática de cenários de aceitação a partir de histórias de usuário ou relatórios de falhas \cite{Pysmennyi2025,Ferreira2025}, bem como para a conversão de especificações BDD em scripts de teste executáveis, como aqueles utilizados em frameworks de automação web \cite{Ferreira2025,Nettur2025}. 
Para otimizar esse processo, diversas técnicas de \textcolor{blue}{prompt engineering}\todo[color=yellow]{traduzir} são aplicadas. O \textcolor{blue}{few-shot prompting}\todo[color=yellow]{traduzir}, por exemplo, ao fornecer exemplos de alta qualidade diretamente no \textit{prompt} \cite{Paduraru2022}, aumenta significativamente a precisão sintática e semântica dos cenários produzidos, superando o desempenho do \textcolor{blue}{zero-shot prompting}\todo[color=yellow]{traduzir} \cite{Karpurapu2024}. O enriquecimento de contexto via \textcolor{blue}{Retrieval-Augmented Generation}\todo[color=yellow]{traduzir} (RAG) permite ao modelo acessar a documentação e conhecimento organizacional relevante \cite{Pysmennyi2025}, garantindo maior aderência à lógica de negócio durante a geração dos testes \cite{Paduraru2025}. Já o \textcolor{blue}{chain-of-thought prompting}\todo[color=yellow]{traduzir}  contribui para melhorar o raciocínio em tarefas complexas, como a criação de valores textuais que obedecem a restrições específicas \cite{Babikian2025}. Complementarmente, agentes de IA têm utilizado interaction bridges para realizar transições bidirecionais entre a sintaxe formal Gherkin e descrições em linguagem natural não formal, facilitando a calreza dos requisitos e reduzindo a curva de aprendizado dos usuários finais \cite{Zhang2025}.


Além da geração textual, técnicas de análise semântica e sintática aprofundada também são aplicadas para avaliar, inspecionar e traduzir cenários BDD. Conforme \citeonline{Pysmennyi2025}, modelos como o BERT, baseados na arquitetura \textcolor{blue}{Transformer}\todo[color=yellow]{traduzir}, têm sido empregados para aprimorar a avaliação de qualidade dos cenários, permitindo detectar ambiguidades e inconsistências com maior objetividade e repetibilidade do que avaliações manuais tradicionalmente oferecem.
 A rotulagem de papéis semânticos (\textit{Semantic Role Labeling} (SRL)) é igualmente relevante, pois identifica os papéis desempenhados pelos elementos de uma sentença (como atores e objetos afetados) \cite{Wang2022} e constitui um componente central em metodologias como o UMTG, voltadas à extração de informações comportamentais e à geração de restrições formais \cite{Wang2022}. Ao ser combinada com técnicas de detecção de similaridade semântica, essa abordagem possibilita a tradução automática de pré e pós-condições em restrições representadas em \textcolor{blue}{Object Constraint Language}\todo[color=yellow]{traduzir}
 (OCL), permitindo automatizar a geração de dados de teste \cite{Wang2022}. 
 Outras técnicas linguísticas, como o \textcolor{blue}{Part-of-Speech Tagging}\todo[color=yellow]{traduzir}, contribuem para identificar classes gramaticais relevantes para análise de rastreabilidade e para orientar mecanismos de perturbação na criação de novos requisitos \cite{Nettur2025,Gudaparthi2023}. 
 Já a detecção de similaridade semântica, por sua vez, auxilia na comparação de frases e na identificação de padrões conceituais, apoiando-se em recursos como VerbNet e WordNet para tratar grandes conjuntos de verbos com poucas regras e auxiliar na criação de restrições formais \cite{Wang2022}.


As técnicas de NLP também desempenham um papel importante no estabelecimento de rastreabilidade entre artefatos de BDD, incluindo requisitos, código e testes. Procedimentos básicos de processamento, como tokenização e reconhecimento de entidades nomeadas, são utilizados para preparar e padronizar artefatos escritos em Gherkin antes de sua análise por modelos avançados \cite{Wang2022}. Métodos baseados em \textcolor{blue}{word embeddings, como Word2Vec,}\todo[color=yellow]{traduzir}, permitem representar palavras-chave em um espaço vetorial, a partir do qual é possível calcular similaridade de cosseno para inferir dependências e relações entre artefatos distintos, como narrativas de requisitos e trechos de código-fonte \cite{Rotaru2023}.

\subsection{De que forma a padronização da nomenclatura e da estrutura dos cenários influencia a identificação de elementos da interface?}


A padronização da nomenclatura e da estrutura dos cenários é fundamental para garantir uma identificação clara e eficiente dos elementos da interface, principalmente em contextos de desenvolvimento e testes orientados por comportamento (BDD) \cite{Paduraru2022, Babikian2025}. A estrutura \textcolor{blue}{“Given-When-Then”,}\todo[color=yellow]{traduzir}
 típica do Gherkin, organiza a escrita dos cenários e deixa explícito o que deve acontecer em cada etapa, ajudando na definição dos critérios de aceitação \cite{Alinezhadtilaki2025, Babikian2025}. Essa clareza faz com que todos os envolvidos no projeto entendam o comportamento esperado do sistema, diminuindo as chances de erro e falhas de comunicação \cite{Alinezhadtilaki2025}.

Essa estrutura também facilita diretamente a automação e a identificação dos elementos da interface por ferramentas e modelos de Inteligência Artificial (IA). Em processos de geração automática de testes de aceitação, por exemplo, Large Language Models (LLMs) conseguem transformar cenários Gherkin em scripts executáveis \cite{Paduraru2025, Ferreira2025}. Uma prática comum e eficiente é orientar o LLM a usar o \textcolor{blue}{data-test-id}\todo[color=yellow]{traduzir} para localizar o elemento correto durante a execução. Assim, a padronização do cenário, ao deixar explícita a ação que deve ser feita, permite mapear essa ação para o elemento técnico da interface que realmente importa \cite{Ferreira2025}.

Além disso, a padronização e o uso de uma linguagem voltada ao usuário, como acontece no BDD e no \textcolor{blue}{Acceptance Test-Driven Development}\todo[color=yellow]{traduzir}
 (ATDD), ajudam as plataformas de automação a separar a lógica do teste da dificuldade de identificar elementos técnicos da interface \cite{Penagos2024}. 
 Quando os cenários estão bem estruturados, ferramentas baseadas em IA e técnicas de NLP conseguem extrair com mais precisão o comportamento descrito, identificar padrões e gerar código alinhado ao que o negócio realmente precisa \cite{Zhang2025}. Isso torna mais fácil transformar instruções em linguagem natural, mesmo com variações na escrita, em ações concretas sobre os elementos do sistema, sugerindo funções, parâmetros e interações coerentes com o que foi especificado \cite{Paduraru2025}.

A padronização dos cenários em BDD/Gherkin funciona como um mapa detalhado. Sem essa estrutura (o \textcolor{blue}{Given-When-Then,}\todo[color=yellow]{traduzir}), o texto seria genérico demais. Mas com ela, a IA entende não só o que deve acontecer (“Então, o sistema deve exibir 12”), mas também o estado inicial (“Dado, a calculadora está pronta”) e o evento que gera a mudança (“Quando, eu somo 5 e 7”). Isso permite identificar com precisão quais elementos da interface estão envolvidos como o botão de soma ou o campo de resultado  e qual identificador técnico (como o \textcolor{blue}{data-test-id,}\todo[color=yellow]{traduzir}) deve ser utilizado em cada ação \cite{Alinezhadtilaki2025, Ferreira2025}.

\textcolor{blue}{user stories,}\todo[color=yellow]{traduzir}

\subsection{Quais ferramentas atuais já tentam automatizar a geração de testes a partir de especificações BDD e como lidam com ambiguidades?}



O \textcolor{blue}{AutoUAT e Test Flow}\todo[color=yellow]{Inserir nota de rodapé com a url da ferramenta} são ferramentas complementares desenvolvidas para automatizar a geração de testes de aceitação para aplicações web. As duas utilizam o modelo GPT-4 Turbo. O AutoUAT foca na geração de cenários de teste de aceitação em linguagem natural (Gherkin) a partir de \textcolor{blue}{user stories,}\todo[color=yellow]{traduzir}. Já o TestFlow pega os cenários Gherkin e, juntamente com a descrição da \textcolor{blue}{user stories,}\todo[color=yellow]{traduzir} e o código HTML das páginas sob teste, gera scripts de teste executáveis usando Cypress em TypeScript. As duas ferramentas são planejadas para suportar o ATDD, permitindo que \textcolor{blue}{testers}\todo[color=yellow]{traduzir} e outras partes interessadas revisem os cenários gerados antes de convertê-los em scripts executáveis, o que melhora a qualidade do teste \cite{Ferreira2025}.

No AutoUAT, a geração de cenários Gherkin é aprimorada por um processo iterativo de \textcolor{blue}{prompt engineering}\todo[color=yellow]{traduzir}, criado para tornar as respostas do modelo mais claras, mais conscientes do contexto da user story e mais específicas em relação ao comportamento esperado. Além disso, o modelo frequentemente identifica casos não explícitos na \textcolor{blue}{user story}\todo[color=yellow]{traduzir}, cobrindo cenários omitidos  uma forma de lidar com ambiguidades implícitas \cite{Ferreira2025}.

\todo[inline, color=pink]{Essa última frase ficou confusa. Reescrever}


No Test Flow, a inclusão do código HTML das páginas sob teste na entrada reduz drasticamente a necessidade de refinamentos manuais para localizar elementos de interface de usuário (UI), o que pode ser uma fonte de erro ou ambiguidade na automação. Quando faltam detalhes ou o cenário é ambíguo, a ferramenta depende de enriquecimento de contexto ou pequenos ajustes manuais, o que é parte do seu mecanismo de resolução de ambiguidades \cite{Ferreira2025}.


BDDTestAIGen, é um framework que utiliza LLMs para automatizar a criação de testes BDD, visando reduzir o esforço manual e envolver \textcolor{blue}{stakeholders}\todo[color=yellow]{traduzir} não técnicos. Ele combina LLMs utilizando um modelo de código aberto ajustado, como o Llama3.1 8B, com técnicas de NLP e IA Agente baseada no formato ReAct. O framework utiliza RAG para incorporar conhecimento interno do projeto, como o código-fonte existente \cite{Paduraru2025}. Além disso, emprega técnicas de NLP como \textcolor{blue}{POS Tagging e Semantic Role Labeling}\todo[color=yellow]{traduzir} para estruturar semanticamente as instruções em linguagem natural, reduzindo ambiguidades linguísticas e permitindo que o modelo identifique corretamente predicados, argumentos e atributos mesmo quando a descrição do usuário é imprecisa \cite{Paduraru2025}.
Esse processo é coordenado passo a passo por um assistente conversacional, com o usuário mantendo o controle total sobre a criação do teste (edição de passos, sugestão de parâmetros). Se o agente de IA não conseguir encontrar uma etapa correspondente implementada, estiver incerto ou não conseguir atribuir todos os parâmetros necessários, o erro é relatado ao usuário, que é solicitado a ajudar a editar a etapa gerada \cite{Paduraru2025}.



A incorporação de conhecimento interno do projeto via RAG, combinada com um mecanismo de similaridade semântica baseado em \textcolor{blue}{embeddings}\todo[color=yellow]{traduzir}, permite que o sistema identifique o passo implementado mais próximo da intenção do usuário, mitigando ambiguidades na correspondência entre texto e código e aumentando a precisão da geração \cite{Paduraru2025}.



\textcolor{blue}{Cypress Copilot}\todo[color=yellow]{Inserir nota de rodapé com a url da ferramenta}, é uma extensão do Visual Studio Code que automatiza a geração de código de testes Cypress seguindo a metodologia BDD. Ela utiliza o modelo GPT-4o com a técnica \textcolor{blue}{few-shot chain prompt}\todo[color=yellow]{traduzir}, na qual o modelo recebe exemplos encadeados de S\textcolor{blue}{Step Definitions e classes Page Object Model}\todo[color=yellow]{traduzir} (POM). Essa estruturação em duas etapas fornece contexto progressivo e orienta o modelo a reproduzir corretamente os padrões de implementação usados em automação BDD \cite{Nettur2025}.Esse mecanismo também funciona como forma de lidar com ambiguidades presentes nos cenários: ao fornecer exemplos reais e estruturados, o modelo passa a interpretar os passos com maior precisão, reduzindo interpretações divergentes, métodos vazios e lacunas de implementação problemas comuns em abordagens \textcolor{blue}{zero-shot}\todo[color=yellow]{traduzir}. Como resultado, o Cypress Copilot gera código mais completo e consistente, com menor incidência de erros e maior aderência ao comportamento esperado da aplicação \cite{Nettur2025}.

As ferramentas atuais mostram que já é possível automatizar testes a partir de BDD, mas ainda com estratégias diferentes para tratar ambiguidades. AutoUAT e Test Flow usam LLMs com engenharia de prompts e enriquecimento de contexto para gerar cenários e scripts mais claros. O BDDTestAIGen combina NLP, RAG e interação orientada ao usuário para estruturar melhor instruções vagas e confirmar passos incertos. Já o Cypress Copilot reduz interpretações equivocadas ao fornecer exemplos encadeados que guiam o modelo a seguir o padrão do projeto. No conjunto, essas soluções mostram que o uso de LLMs aliado a mecanismos de validação e estruturação semântica é hoje a principal forma de mitigar ambiguidades na automação de testes BDD.

\todo[inline, color=pink]{Referenciem a última frase}

\subsection{Como modelos semânticos são utilizados em sistemas de IA para reduzir ambiguidades na interpretação de especificações em linguagem natural, como as descritas em BDD?}

A interpretação de especificações em linguagem natural, como cenários BDD, exige mecanismos que reduzam ambiguidades e tornem o comportamento descrito mais claro para sistemas de IA. Modelos semânticos atuam nesse processo ao identificar relações essenciais e estruturar o texto de forma interpretável por agentes automatizados. As principais técnicas utilizadas são apresentadas a seguir.

Grandes Modelos de Linguagem baseados em transformadores, como BERT e GPT, são fundamentais para interpretar a semântica de cenários escritos em linguagem natural, permitindo maior precisão e consistência na análise de requisitos \cite{Chemnitz2023}. Esses modelos reduzem subjetividades ao avaliar cenários BDD, oferecendo validações estruturadas e repetíveis \cite{Alinezhadtilaki2025}. Além disso, utilizam compreensão semântica para gerar artefatos de software, como casos de teste derivados de histórias de usuário \cite{Ferreira2025}. Em abordagens generativas, cenários BDD funcionam como uma ponte entre linguagem natural e código, orientando processos de geração automática \cite{Zhang2025}, especialmente graças à estrutura “Dado, Quando, Então”, que facilita a interpretação \cite{Paduraru2025}.

Além desses modelos semânticos, técnicas clássicas de rotulagem de papéis semânticos (SRL) também contribuem para a redução de ambiguidades ao identificar automaticamente os papéis desempenhados por cada termo da frase como agente, alvo e ação. Isso permite transformar descrições informais em estruturas mais claras e consistentes, facilitando que sistemas de IA interpretem corretamente “quem faz o quê”, independentemente da ordem ou variação sintática das sentenças \cite{Wang2022}.

Outra técnica relevante é a detecção de similaridade semântica, empregada para lidar com variações linguísticas comuns em cenários BDD. Expressões diferentes, mas semanticamente equivalentes, são reconhecidas como tendo o mesmo significado. Para isso, utilizam-se recursos como redes lexicais e bases de relações semânticas entre verbos e substantivos, que agrupam termos semelhantes e auxiliam na interpretação consistente das instruções presentes nos cenários \cite{Wang2022}. Esse mecanismo reduz confusões geradas por sinonímias ou escolhas lexicais variadas, aumentando a precisão da interpretação automatizada.

\subsection{Como a complexidade do projeto da interface gráfica do usuário englobando a quantidade de elementos, a densidade visual e a inconsistência de layout impacta a precisão e a cobertura de um LLM ao identificar elementos para gerar testes automatizados baseados BDD?} 

A representação do estado da interface pelo agente baseia-se na combinação de extração do \textcolor{blue}{DOM}\todo[color=yellow]{O que é isso mesmo?}, reconhecimento visual e processamento textual, o que reforça que aplicações web dinâmicas apresentam desafios significativos para agentes autônomos de teste \cite{Mughal2025}. 

Interfaces dinâmicas, especialmente em aplicações web, sofrem atualizações frequentes que tornam \textcolor{blue}{x-paths}\todo[color=yellow]{????} e \textcolor{blue}{seletores instáveis}\todo[color=yellow]{O que são seletores instáveis?}, elevando o risco de erros de identificação e prejudicando a execução de testes automatizados \cite{Pysmennyi2025}.

Apesar dessas limitações técnicas relacionadas à interface, a precisão e a cobertura dos testes gerados também dependem da clareza das especificações escritas em BDD. Testes gerados por IA são influenciados principalmente pela qualidade das \textcolor{blue}{user stories}\todo[color=yellow]{traduzir} e dos cenários Gherkin, mais do que pela complexidade visual da interface \cite{Ferreira2025}. A falta de contexto nos cenários pode resultar em erros de execução, dificultando que a IA associe corretamente cada ação aos elementos correspondentes na tela \cite{Ferreira2025}.

\todo[inline, color=pink]{Os critérios de aceitação são determinantes para a escrita dos cenários BDD. Se houver uma descrição de história sem critérios, de nada adianta. Explicar isso melhor no parágrafo anterior.}

Por fim, embora aspectos como densidade visual e número de elementos possam aumentar o esforço de interpretação por parte da IA, a literatura analisada demonstra que o fator mais determinante para a precisão e cobertura dos testes gerados automaticamente continua sendo a qualidade das especificações comportamentais fornecidas.

\subsection{Como diferentes estilos de escrita (linguagem natural vs. linguagem técnica) em cenários BDD influenciam a interpretação automática pela IA?}

\subsubsection{Linguagem Natural Informal}

A qualidade da interpretação realizada pela IA está diretamente relacionada à clareza e ao contexto fornecidos nos cenários Gherkin e nas histórias de usuário \cite{Ferreira2025}. O uso de termos vagos na escrita do BDD gera ambiguidades que dificultam a compreensão da IA \cite{Alinezhadtilaki2025}.



Frases imprecisas e terminologia inconsistente podem provocar falhas na geração automática de restrições em abordagens que utilizam PLN, como o \textcolor{blue}{Semantic Role Labeling}\todo[color=yellow]{traduzir} (SRL), para traduzir o texto em restrições formais, como OCL \cite{Wang2022}. A falta de precisão na redação dos requisitos pode levar os agentes de IA a não interpretar corretamente as informações, resultando em código defeituoso ou desconectado do objetivo real, exigindo intervenção humana para correções \cite{Zhang2025}.



 \textcolor{blue}{Modelos de grande porte}\todo[color=yellow]{Utilizem a mesma tradução feita anteriormente} (LLMs) que recebem cenários via \textcolor{blue}{zero-shot prompting}\todo[color=yellow]{traduzir}, ou seja, sem exemplos, demonstraram uma incidência significativamente maior de erros de sintaxe  representando 89\% dos erros observados em um \textcolor{blue}{estudo}\todo[color=yellow]{Qual estudo?}  além de inconsistências no formato de saída, o que exige engenharia de \textit{prompt} cuidadosa ou pós-processamento \cite{Karpurapu2024}.

\subsubsection{Descrições Estruturadas e Técnicas}



A utilização do formato \textcolor{blue}{“Given, When, Then”}\todo[color=yellow]{traduzir}  na escrita de cenários é uma prática essencial para a \textcolor{blue}{essencial para a qualidade do software}\todo[color=yellow]{Como assim? Qualidade de software é muita coisa}, pois garante que todos os membros da equipe compreendam claramente o resultado esperado \cite{Alinezhadtilaki2025}.


LLMs como GPT-3.5 e GPT-4 apresentam melhor desempenho quando são empregadas técnicas de \textcolor{blue}{few-shot prompting}\todo[color=yellow]{traduzir}, nas quais exemplos estruturados são fornecidos dentro do prompt \cite{Karpurapu2024}. O uso de técnicas como o \textcolor{blue}{few-shot chain prompt}\todo[color=yellow]{traduzir} demonstrou desempenho superior, gerando código mais completo, mais fácil de manter e com menos erros de sintaxe \cite{Nettur2025}.

\todo[inline, color=pink]{Fiquei com a mesma sensação disso já ter sido respondido em uma questão anterior. Verifiquem cuidadosamente isso.}

Em abordagens como a \textcolor{blue}{UMTG}\todo[color=yellow]{?????} , que geram casos de teste executáveis a partir de especificações de caso de uso, o emprego de um formato estruturado (RUCM), com palavras-chave e regras de restrição, contribuiu para reduzir ambiguidades e permitiu a análise e extração automatizada de informações comportamentais. Isso garantiu à IA informações suficientes para o processo de automação \cite{Wang2022}.

Além disso, o uso da linguagem Gherkin para descrever histórias de usuário, incluindo critérios de aceitação bem definidos, funciona como uma ponte para manter a consistência semântica entre os requisitos e o código gerado pelo agente de IA \cite{Zhang2025}.

\subsubsection{Impacto dos Estilos de Escrita na Interpretação pela IA}
 

A linguagem natural informal aumenta a ambiguidade e dificulta que a IA identifique ações, pré-condições e resultados esperados, resultando em interpretações inconsistentes. Em contraste, a linguagem técnica e estruturada  como Gherkin e RUCM  fornece padrões previsíveis que facilitam o \textcolor{blue}{parsing}\todo[color=yellow]{traduzir}, reduzem erros semânticos e permitem melhor geração automática de testes ou código. Assim, quanto mais estruturado o cenário, maior a precisão da interpretação realizada pela IA.

\subsection{Quais fatores limitam a adoção em larga escala de soluções baseadas em IA para transformar especificações BDD em testes de sistema automatizados na indústria de software?}

Agentes de IA tendem a se desviar de cenários de teste negativos, tentando “corrigir” o fluxo para alcançar um resultado positivo, que pode mascarar falhas potenciais. Como grande parte das LLMs operam como uma “caixa-preta”, torna-se difícil compreender exatamente como e por que um teste foi gerado \cite{Pysmennyi2025}.

Sistemas baseados em IA generativa comportam-se de maneira probabilística, podendo produzir saídas inesperadas, conhecidas como alucinações. Esse comportamento não determinístico é problemático, pois a execução de um mesmo teste em momentos diferentes pode resultar em saídas distintas quando o modelo é estocástico ou dependente de estado (\textit{stateful}). LLMs podem gerar saídas aparentemente plausíveis, mas totalmente incorretas, o que complica o processo de validação \cite{Freeman2025}. Além disso, essas LLMs apresentam dificuldade em satisfazer integralmente as restrições especificadas nos requisitos e em identificar inconsistências entre eles, especialmente quando comparadas a solvers formais \cite{Babikian2025}.

O custo computacional e a dependência da disponibilidade de APIs continuam sendo restrições práticas à adoção dessas soluções \cite{Pysmennyi2025}. O custo costuma ser proporcional ao número de tokens utilizados na geração de um caso de teste. Além disso, embora modelos menores (como o Llama3.1 8B) possam ser executados em máquinas do usuário, a latência em CPU  cerca de 3 segundos por etapa  pode comprometer a experiência, sobretudo quando comparada ao desempenho quase instantâneo obtido com GPUs dedicadas \cite{Paduraru2025}.

Há também dificuldades relacionadas ao uso de modelos com grandes janelas de contexto, exigindo estratégias de filtragem e poda (\textit{pruning}) antes das chamadas ao LLM \cite{Paduraru2025}. Além disso, garantir entradas contextuais detalhadas  como descrições completas do produto e elementos da interface do usuário (UI)  é um desafio que afeta diretamente a precisão da geração \cite{Ferreira2025}.

Mesmo com LLMs, os testes gerados ainda requerem intervenção humana para garantir precisão. O agente de IA pode não localizar uma etapa correspondente já implementada, apresentar incertezas ou não conseguir identificar todos os parâmetros adequados, exigindo que o usuário edite ou confirme a etapa sugerida \cite{Paduraru2025}.

A utilização de IA generativa também pode gerar preocupações relacionadas à segurança dos dados, especialmente quando os cenários envolvem sistemas críticos \cite{Ferreira2025}. Além disso, integrar essas soluções às pipelines de Integração e Entrega Contínuas (CI/CD) pode demandar customizações específicas, dependendo das características de cada pipeline \cite{Ferreira2025}.

\todo[inline, color=pink]{Não fiquei convencido que essas questões impedem mesmo a adoção em larga escala, principalmente a justificativa do custo computacional. Do ponto de vista do usuário, basta abrir um prompt desses e tentar gerar. Não fica claro de fato, quais fatores limitam a adoção em larga escala. }