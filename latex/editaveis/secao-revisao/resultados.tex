\section{Resultados}
\label{sec:rsl-resultados}

Após a definição da string de busca e a seleção inicial dos estudos, procedeu-se à extração dos dados por meio do formulário disponibilizado na plataforma Parsifal, escolhida por oferecer recursos que facilitam a condução estruturada de revisões na Engenharia de Software. Cada artigo incluído teve suas informações registradas no formulário, permitindo padronizar a coleta de dados relevantes. Concluída essa etapa, os resultados foram consolidados em uma planilha pública, na qual cada linha corresponde a um estudo selecionado e cada coluna representa um dos campos definidos previamente no protocolo de extração. Essa organização possibilitou analisar de maneira sistemática os aspectos necessários ao atendimento das questões de pesquisa. Nas subseções seguintes, são apresentadas as sínteses obtidas a partir dessa extração.

\subsection{Quais padrões e boas práticas de escrita em BDD já são utilizados para reduzir ambiguidades em cenários de teste?}

Os padrões e boas práticas de escrita em Behavior-Driven Development (BDD) desempenham um papel central na estruturação e no refinamento de cenários de teste, constituindo um mecanismo essencial para reduzir ambiguidades e promover um entendimento compartilhado entre stakeholders técnicos e não técnicos \cite{Alinezhadtilaki2025}. O elemento estruturante desse processo é a linguagem Gherkin, cuja natureza semiestruturada e legível \cite{Karpurapu2024} por humanos permite descrever comportamentos de forma clara e consistente \cite{Alinezhadtilaki2025} . O padrão fundamental utilizado é o modelo Given-When-Then, que define o comportamento esperado do sistema: o Given estabelece o contexto inicial ou as pré-condições relevantes; o When descreve a ação executada pelo usuário ou pelo sistema que desencadeia o comportamento analisado; e o Then especifica o resultado esperado após a conclusão da ação \cite{GUPTA2023102141}.

Segundo \cite{Alinezhadtilaki2025}, a escrita eficaz de cenários BDD depende da adesão rigorosa a essa estrutura e da clareza da linguagem empregada, de modo a minimizar subjetividades e eliminar ambiguidades. A conformidade estrita com o formato “Given, When, Then” contribui para a uniformidade da comunicação entre equipes, reduzindo falhas interpretativas e inconsistências na implementação. Além disso, espera-se que os cenários apresentem atributos como unicidade, integridade, clareza e foco, de forma que a descrição dos comportamentos seja acessível e facilmente operacionalizável. Outro princípio importante é a restrição da granularidade: cada cenário deve contemplar apenas uma ação realizada por um único tipo de usuário sobre um único objeto \cite{GUPTA2023102141}. Caso múltiplas ações ou objetos sejam envolvidos, recomenda-se a decomposição em cenários menores e mais específicos \cite{GUPTA2023102141}. Para ampliar a reutilização e abrangência dos testes, emprega-se também o padrão Scenario Outline \cite{Paduraru2025}, associado a tabelas de Examples, o que possibilita testar diversas instâncias de um mesmo modelo de comportamento sem redundância. A isso somam-se modelos de requisitos restritos, como o RUCM (Restricted Use Case Modeling) \cite{Wang2022}, que, ao incorporar templates com palavras-chave e regras rígidas de construção, contribuem para reduzir imprecisões e aumentar o potencial de análise automatizada das especificações, mesmo permitindo o uso do vocabulário completo do inglês desde que com complexidade sintática limitada.

A utilização de técnicas e ferramentas de suporte, especialmente com a incorporação de recursos de Inteligência Artificial, tem se mostrado decisiva para garantir a consistência dos padrões de escrita e a mitigação de ambiguidades. Ferramentas de validação sintática, como o Gherkin-lint \cite{Karpurapu2024}, são usadas para identificar violações de sintaxe e assegurar conformidade com diretrizes de estilo, superando limitações inerentes à revisão manual. Na geração automatizada de cenários BDD por meio de Large Language Models (LLMs), destaca-se o uso de few-shot prompting \cite{Karpurapu2024}, técnica que, ao fornecer exemplos previamente curados, aumenta a precisão dos cenários produzidos e reduz erros sintáticos \cite{Karpurapu2024}. Adicionalmente, métodos de Retrieval-Augmented Generation (RAG) enriquecem o contexto fornecido aos modelos com dados internos, como documentação e conhecimento organizacional, resultando em cenários mais completos e alinhados com a lógica de negócio \cite{Pysmennyi2025}. A participação humana por meio da abordagem human-in-the-loop permanece indispensável, pois permite que especialistas revisem, ajustem e validem os cenários gerados, garantindo sua aderência ao comportamento esperado do sistema \cite{Pysmennyi2025}.

\subsection{Quais são os principais desafios técnicos enfrentados por sistemas de IA na interpretação de especificações BDD para identificar elementos da interface gráfica?}

Os sistemas de Inteligência Artificial (IA), em especial os Large Language Models (LLMs) e agentes autônomos, enfrentam desafios técnicos substanciais ao interpretar especificações em Behavior-Driven Development (BDD) para identificar e interagir com elementos de Interfaces Gráficas do Usuário (GUIs). Esses desafios concentram-se principalmente na tradução de linguagem natural para ações concretas, na necessidade de lidar com a natureza dinâmica e visual das interfaces modernas e nas limitações inerentes dos próprios modelos de IA. 

A interpretação das especificações escritas em Gherkin envolve dificuldades semânticas e contextuais significativas. Entre elas, destaca-se o mapeamento inconsistente entre instruções em linguagem natural e as funcionalidades do sistema, bem como os parâmetros adequados para operar sobre os elementos da GUI \cite{Paduraru2025}, o que ocorre com frequência quando o modelo não é orientado por prompts otimizados \cite{Pysmennyi2025}. Soma-se a isso a presença de ambiguidades ou lacunas de contexto, onde a IA frequentemente não reconhece critérios de aceitação implícitos que não foram explicitamente registrados no cenário BDD, como a necessidade de solicitar confirmação ao usuário \cite{Zhang2025}. Outro desafio decorre da inconsistência de vocabulário e do uso de termos técnicos, especialmente quando nomes de classes, atributos ou métodos são compostos por acrônimos ou apresentam ambiguidades estruturais, o que dificulta a correspondência correta com os elementos de software \cite{Wang2022}. Problemas adicionais surgem da conversão de valores expressos em linguagem natural para tipos de dados esperados pelas funções do sistema, como na compatibilização de parâmetros com unidades de medida distintas ou nomenclaturas pouco transparentes \cite{Paduraru2025}. Ademais, os LLMs podem perder o foco na lógica de negócio essencial quando expostos a muitos detalhes contextuais, gerando código que, embora coerente com o cenário BDD, negligencia funcionalidades básicas \cite{Zhang2025}.

Além das dificuldades linguísticas, os sistemas de IA enfrentam barreiras relacionadas à interpretação visual e à adaptação dinâmica exigida por interfaces gráficas contemporâneas. A navegação em ambientes com estruturas complexas, estados interdependentes e elementos sensíveis ao contexto ultrapassa a capacidade dos métodos tradicionais de teste e requer agentes capazes de ajustar seu comportamento dinamicamente \cite{Mughal2025}. A seleção de observações relevantes constitui outra dificuldade, especialmente em contextos visuais complexos, como videogames ou GUIs ricas em elementos gráficos, nos quais a definição de funções de recompensa adequadas e a filtragem de sinais pertinentes são desafios típicos para abordagens de Reinforcement Learning (RL) \cite{Mastain2024}. Além disso, efeitos gráficos intensos, partículas e elementos visuais sobrepostos podem afetar ferramentas baseadas em visão computacional, dificultando a detecção de objetos, a identificação de estados relevantes ou a interpretação precisa de elementos que aparecem em condições de alta intensidade visual \cite{Paduraru2022}.

Por fim, as limitações estruturais dos próprios modelos de IA introduzem desafios adicionais. A natureza de “caixa preta” dos LLMs dificulta a obtenção de explicações claras sobre suas decisões, tornando mais complexa a depuração e o projeto de casos de teste \cite{Pysmennyi2025}. O comportamento probabilístico desses modelos resulta em não determinismo e na ocorrência de hallucinations, isto é, respostas plausíveis porém incorretas, o que complica o processo de validação, já que nem sempre é evidente qual deveria ser o resultado esperado \cite{Freeman2025}. Modelos menores também enfrentam limitações de planejamento e raciocínio, podendo entrar em ciclos improdutivos ou ficar presos na execução repetitiva de subtarefas quando confrontados com problemas complexos que exigem raciocínio multietapas \cite{Pysmennyi2025}. Adicionalmente, agentes de IA tendem a evitar cenários de teste negativos ao tentar “corrigir” o fluxo de execução para alcançar um resultado positivo, o que pode mascarar falhas críticas e aumentar o risco de falsos negativos \cite{Pysmennyi2025}.

\subsection{Quais são os principais desafios técnicos enfrentados por sistemas de IA na interpretação de especificações BDD para identificar elementos da interface gráfica?}

As técnicas de Processamento de Linguagem Natural (NLP) têm desempenhado um papel fundamental no aprimoramento da interpretação automática de requisitos e cenários em Behavior-Driven Development (BDD), especialmente com o avanço dos Large Language Models (LLMs). Essas técnicas buscam traduzir construções em linguagem natural (particularmente aquelas expressas em Gherkin) em formatos estruturados, verificáveis e automatizáveis, contribuindo para maior eficiência e qualidade no ciclo de testes. Entre as abordagens mais relevantes, destacam-se as aplicações diretas de LLMs, que atuam como motores para a interpretação e geração de artefatos BDD graças à sua capacidade de compreensão contextual da linguagem natural. Os modelos têm sido amplamente utilizados para a geração automática de cenários de aceitação a partir de user stories ou relatórios de falhas \cite{Pysmennyi2025,Ferreira2025}, bem como para a conversão de especificações BDD em scripts de teste executáveis, como aqueles utilizados em frameworks de automação web \cite{Ferreira2025,Nettur2025}. Para otimizar esse processo, diversas técnicas de prompt engineering são aplicadas. O few-shot prompting, por exemplo, ao fornecer exemplos de alta qualidade diretamente no prompt \cite{Paduraru2022}, aumenta significativamente a precisão sintática e semântica dos cenários produzidos, superando o desempenho do zero-shot prompting \cite{Karpurapu2024}. O enriquecimento de contexto via Retrieval-Augmented Generation (RAG) permite ao modelo acessar documentação e conhecimento organizacional relevante \cite{Pysmennyi2025}, garantindo maior aderência à lógica de negócio durante a geração dos testes \cite{Paduraru2025}. Já o chain-of-thought prompting contribui para melhorar o raciocínio em tarefas complexas, como a criação de valores textuais que obedecem a restrições específicas \cite{Babikian2025}. Complementarmente, agentes de IA têm utilizado interaction bridges para realizar transições bidirecionais entre a sintaxe formal de Gherkin e descrições em linguagem natural não formal, facilitando a clarificação dos requisitos e reduzindo a curva de aprendizado dos usuários finais \cite{Zhang2025}.

Além da geração textual, técnicas de análise semântica e sintática aprofundada também são aplicadas para avaliar, inspecionar e traduzir cenários BDD. Conforme \citeonline{Pysmennyi2025}, modelos como o BERT, baseados na arquitetura Transformer, têm sido empregados para aprimorar a avaliação de qualidade dos cenários, permitindo detectar ambiguidades e inconsistências com maior objetividade e repetibilidade do que avaliações manuais tradicionalmente oferecem. A rotulagem de papéis semânticos (Semantic Role Labeling (SRL)) é igualmente relevante, pois identifica os papéis desempenhados pelos elementos de uma sentença (como atores e objetos afetados) \cite{Wang2022} e constitui um componente central em metodologias como o UMTG, voltadas à extração de informações comportamentais e à geração de restrições formais \cite{Wang2022}. Ao ser combinada com técnicas de detecção de similaridade semântica, essa abordagem possibilita a tradução automática de pré e pós-condições em restrições representadas em Object Constraint Language (OCL), permitindo automatizar a geração de dados de teste \cite{Wang2022}. Outras técnicas linguísticas, como o Part-of-Speech Tagging, contribuem para identificar classes gramaticais relevantes para análise de rastreabilidade e para orientar mecanismos de perturbação na criação de novos requisitos \cite{Nettur2025,Gudaparthi2023}. A detecção de similaridade semântica, por sua vez, auxilia na comparação de frases e na identificação de padrões conceituais, apoiando-se em recursos como VerbNet e WordNet para tratar grandes conjuntos de verbos com poucas regras e auxiliar na criação de restrições formais \cite{Wang2022}.

As técnicas de NLP também desempenham um papel importante no estabelecimento de rastreabilidade entre artefatos de BDD, incluindo requisitos, código e testes. Procedimentos básicos de processamento, como tokenização e reconhecimento de entidades nomeadas, são utilizados para preparar e padronizar artefatos escritos em Gherkin antes de sua análise por modelos avançados \cite{Wang2022}. Métodos baseados em word embeddings, como Word2Vec, permitem representar palavras-chave em um espaço vetorial, a partir do qual é possível calcular similaridade de cosseno para inferir dependências e relações entre artefatos distintos, como narrativas de requisitos e trechos de código-fonte \cite{Rotaru2023}.

\subsection{De que forma a padronização da nomenclatura e da estrutura dos cenários influencia a identificação de elementos da interface?}

A padronização da nomenclatura e da estrutura dos cenários é fundamental para garantir uma identificação clara e eficiente dos elementos da interface, principalmente em contextos de desenvolvimento e testes orientados por comportamento (Behavior-Driven Development, BDD)\cite{Paduraru2025, Babikian2025}. A estrutura “Given-When-Then”, típica do Gherkin, organiza a escrita dos cenários e deixa explícito o que deve acontecer em cada etapa, ajudando na definição dos critérios de aceitação \cite{Alinezhadtilaki2025, Babikian2025}. Essa clareza faz com que todos os envolvidos no projeto entendam o comportamento esperado do sistema, diminuindo as chances de erro e falhas de comunicação \cite{Alinezhadtilaki2025}.

Essa estrutura também facilita diretamente a automação e a identificação dos elementos da interface por ferramentas e modelos de Inteligência Artificial. Em processos de geração automática de testes de aceitação, por exemplo, Large Language Models (LLMs) conseguem transformar cenários Gherkin em scripts executáveis \cite{Paduraru2025, Ferreira2025}. Uma prática comum e eficiente é orientar o LLM a usar o data-test-id para localizar o elemento correto durante a execução. Assim, a padronização do cenário, ao deixar explícita a ação que deve ser feita, permite mapear essa ação para o elemento técnico da interface que realmente importa \cite{Ferreira2025}.

Além disso, a padronização e o uso de uma linguagem voltada ao usuário, como acontece no BDD e no Acceptance Test-Driven Development (ATDD), ajudam as plataformas de automação a separar a lógica do teste da dificuldade de identificar elementos técnicos da interface \cite{Penagos2024}. Quando os cenários estão bem estruturados, ferramentas baseadas em IA e técnicas de NLP conseguem extrair com mais precisão o comportamento descrito, identificar padrões e gerar código alinhado ao que o negócio realmente precisa \cite{Zhang2025}. Isso torna mais fácil transformar instruções em linguagem natural, mesmo com variações na escrita, em ações concretas sobre os elementos do sistema, sugerindo funções, parâmetros e interações coerentes com o que foi especificado \cite{Paduraru2025}.

A padronização dos cenários em BDD/Gherkin funciona como um mapa detalhado. Sem essa estrutura (o Given-When-Then), o texto seria genérico demais. Mas com ela, a IA entende não só o que deve acontecer (“Então, o sistema deve exibir 12”), mas também o estado inicial (“Dado, a calculadora está pronta”) e o evento que gera a mudança (“Quando, eu somo 5 e 7”). Isso permite identificar com precisão quais elementos da interface estão envolvidos como o botão de soma ou o campo de resultado e qual identificador técnico como o data-test-id deve ser utilizado em cada ação \cite{Alinezhadtilaki2025, Wang2022}.

\subsection{Quais ferramentas atuais já tentam automatizar a geração de testes a partir de especificações BDD e como lidam com ambiguidades?}

O AutoUAT e Test Flow são ferramentas complementares desenvolvidas para automatizar a geração de testes de aceitação para aplicações web. As duas utilizam o modelo GPT-4 Turbo. O AutoUAT foca na geração de cenários de teste de aceitação em linguagem natural (Gherkin) a partir de user stories. Já o TestFlow pega os cenários Gherkin e, juntamente com a descrição da user story e o código HTML das páginas sob teste, gera scripts de teste executáveis usando Cypress em TypeScript. As duas ferramentas são planejadas para suportar o ATDD, permitindo que testers e outras partes interessadas revisem os cenários gerados antes de convertê-los em scripts executáveis, o que melhora a qualidade do teste \cite{Ferreira2025}.

No AutoUAT, a geração de cenários Gherkin é aprimorada por um processo iterativo de prompt engineering, criado para tornar as respostas do modelo mais claras, mais conscientes do contexto da user story e mais específicas em relação ao comportamento esperado. Além disso, o modelo frequentemente identifica casos não explícitos na user story, cobrindo cenários omitidos uma forma de lidar com ambiguidades implícitas \cite{Ferreira2025}.

No Test Flow, a inclusão do código HTML das páginas sob teste na entrada reduz drasticamente a necessidade de refinamentos manuais para localizar elementos de interface de usuário (UI), o que pode ser uma fonte de erro ou ambiguidade na automação. Quando faltam detalhes ou o cenário é ambíguo, a ferramenta depende de enriquecimento de contexto ou pequenos ajustes manuais, o que é parte do seu mecanismo de resolução de ambiguidades \cite{Ferreira2025}.



O BDDTestAIGen é um framework que utiliza LLMs para automatizar a criação de testes BDD, visando reduzir o esforço manual e envolver stakeholders não técnicos. Ele combina LLMs utilizando um modelo de código aberto ajustado, como o Llama3.1 8B, com técnicas de NLP e IA Agente baseada no formato ReAct. O framework utiliza RAG (Retrieval-Augmented Generation) para incorporar conhecimento interno do projeto, como o código-fonte existente \cite{Paduraru2025}.

Além disso, emprega técnicas de NLP como POS Tagging e Semantic Role Labeling para estruturar semanticamente as instruções em linguagem natural, reduzindo ambiguidades linguísticas e permitindo que o modelo identifique corretamente predicados, argumentos e atributos mesmo quando a descrição do usuário é imprecisa \cite{Paduraru2025}.

O processo é coordenado passo a passo por um assistente conversacional, com o usuário mantendo o controle total sobre a criação do teste (edição de passos, sugestão de parâmetros). Se o agente de IA não conseguir encontrar uma etapa correspondente implementada, estiver incerto ou não conseguir atribuir todos os parâmetros necessários, o erro é relatado ao usuário, que é solicitado a ajudar a editar a etapa gerada \cite{Paduraru2025}.

A incorporação de conhecimento interno do projeto via RAG, combinada com um mecanismo de similaridade semântica baseado em embeddings, permite que o sistema identifique o passo implementado mais próximo da intenção do usuário, mitigando ambiguidades na correspondência entre texto e código e aumentando a precisão da geração \cite{Paduraru2025}.



O Cypress Copilot uma extensão do Visual Studio Code que automatiza a geração de código de testes Cypress seguindo a metodologia BDD. Ela utiliza o modelo GPT-4o com a técnica few-shot chain prompt, na qual o modelo recebe exemplos encadeados de Step Definitions e classes Page Object Model (POM). Essa estruturação em duas etapas fornece contexto progressivo e orienta o modelo a reproduzir corretamente os padrões de implementação usados em automação BDD \cite{Nettur2025}.

Esse mecanismo também funciona como forma de lidar com ambiguidades presentes nos cenários: ao fornecer exemplos reais e estruturados, o modelo passa a interpretar os passos com maior precisão, reduzindo interpretações divergentes, métodos vazios e lacunas de implementação problemas comuns em abordagens zero-shot. Como resultado, o Cypress Copilot gera código mais completo e consistente, com menor incidência de erros e maior aderência ao comportamento esperado da aplicação \cite{Nettur2025}.

As ferramentas atuais mostram que já é possível automatizar testes a partir de BDD, mas ainda com estratégias diferentes para tratar ambiguidades. AutoUAT e Test Flow usam LLMs com engenharia de prompts e enriquecimento de contexto para gerar cenários e scripts mais claros. O BDDTestAIGen combina NLP, RAG e interação orientada ao usuário para estruturar melhor instruções vagas e confirmar passos incertos. Já o Cypress Copilot reduz interpretações equivocadas ao fornecer exemplos encadeados que guiam o modelo a seguir o padrão do projeto. No conjunto, essas soluções mostram que o uso de LLMs aliado a mecanismos de validação e estruturação semântica é hoje a principal forma de mitigar ambiguidades na automação de testes BDD.

\subsection{Como modelos semânticos são utilizados em sistemas de IA para reduzir ambiguidades na interpretação de especificações em linguagem natural, como as descritas em BDD?}

